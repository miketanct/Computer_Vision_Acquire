{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Computer Vision\n",
    "*Version 1.1*\n",
    "\n",
    "To navigate up and down, you can use the up and down arrow keys on your keyboard<br />\n",
    "To execute code in this workbook, select the code block and press **Shift+Enter** <br />\n",
    "To edit the code block, press enter. \n",
    "\n",
    "The codes in this workbook are cumulative. (Variables defined continue to be available until the notebook is closed) <br />\n",
    "So do start from the top and work your way down to avoid unexpected results!\n",
    "\n",
    "\n",
    "For more help on using Jupyter Notebook, you can click on Help > User Interface Tour in the menu above, <br />\n",
    "or visit https://jupyter-notebook.readthedocs.io/en/stable/ui_components.html\n",
    "\n",
    "Experiment and test out your ideas, for that is one of the fastest ways to learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How do computers see?\n",
    "When you played the icebreaker earlier, your classmate could not talk but you could easily identify your classmate based on what was written on his/her wristband. You used your eyes to see, and your brain processed that information. \n",
    "\n",
    "Can we get a computer to do something similar? \n",
    "<br />\n",
    "Where do we even start?\n",
    "\n",
    "Similar to how we recognized our friends, there are 2 parts.<br />\n",
    "1) Seeing with your eyes<br />\n",
    "2) Making sense of what we see (recognizing your friend, or what he/she wrote or drew on the wristband)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started with code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, we will be using the IntelÂ® Distribution for Python and OpenCV.\n",
    "\n",
    "Another useful Python library will be the Numpy library, which is very useful for quick array manipulations. Images are actually stored as arrays/matrices of pixels, and hence, Numpy would be very useful for helping us to do faster image processing.\n",
    "\n",
    "If you have no prior experience with Python and Numpy, <br />\n",
    "you can get a good introduction online at https://www.datacamp.com/courses/intro-to-python-for-data-science\n",
    "\n",
    "To execute the code block below, select it and press **Shift+Enter**  <br />\n",
    "The results of your execution will be printed directly below the code block. In this case, it will show you your installed version of OpenCV and Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have successfully installed OpenCV version 4.0.0\n",
      "Your version of Python is 3.6.5 |Intel Corporation| (default, Aug  3 2018, 09:40:47) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import cv2              #Import the OpenCV Library\n",
    "import numpy as np      #Import the Numpy library\n",
    "import sys\n",
    "\n",
    "print (\"You have successfully installed OpenCV version \"+cv2.__version__)\n",
    "print (\"Your version of Python is \" + sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Seeing. Let's display our first picture!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"images/image001.png\")   #Load the image file into memory\n",
    "cv2.imshow(\"Image\", img)                  #Display that image\n",
    "\n",
    "cv2.waitKey(0)                            #Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (img[:,:,2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think the computer understands what is in the image at this stage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1b Instead of just a picture, how about using your webcam?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    ret, frame = camera.read()             # Capture frame from camera   \n",
    "    cv2.imshow('Press Spacebar to Exit',frame)              # Display the frame\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):  # Stop if spacebar is detected\n",
    "        break\n",
    "\n",
    "camera.release()                           # Cleanup after spacebar is detected.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you see yourself on the screen? Are you getting excited with ideas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Making sense of what we see\n",
    "\n",
    "So we have quickly achieved the first part of seeing. Now the computer needs to make sense of what it sees.\n",
    "\n",
    "Remember Numpy? In OpenCV, images are stored as Numpy Arrays.\n",
    "\n",
    "These arrays have built in methods that you can use to quickly analyze your image.<br />\n",
    "For example, **.shape** would tell you the dimensions of the Numpy array where the image is stored. (height, width, channels)<br />\n",
    "There are also various other advanced array manipulation techniques, but we'll keep it simple for now.\n",
    "\n",
    "By default, there are 3 channels to store the pixel intensities of Blue, Green, and Red. This is the default colour space used by OpenCV.\n",
    "\n",
    "For the image you displayed above, What are the dimensions? What colour is it at different parts of the image? How are colour intensities represented?\n",
    "\n",
    "<img src=\"images/image001.png\" alt=\"Drawing\" style=\"width: 400px; border:1px solid; float:left;\"/>\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "Try understanding the image for yourself below!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)         #What are the dimensions of this image? \n",
    "                         #What is the width, What is the height, How many channels are there?\n",
    "                         #Hint: Images are represented in Numpy arrays as (height,width,channels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img[0,0])          #What is the colour of the top left corner of the image? Notice that array indexing starts from 0\n",
    "                         #Hint: the channels are represented as Blue,Green,Red by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img[0,799])        #What is the colour of the top right corner of the image? \n",
    "                         #Hint: Notice that the rightmost pixel is 799 not 800. Numpy array indexing starts from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img[300,400])      #What is the colour in the middle of the image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think the computer understands that there are squares and circles in the image at this stage?<br />\n",
    "Or is it only aware that there are rows and rows of pixel intensities that seem to have values from 0 to 255?\n",
    "\n",
    "Yes, by the way, the pixel intensities from 0 to 255 are basically how much of a particular colour is present. <br />\n",
    "0 means that the intensity is 0 (basically dark), while 255 means that it is full of that colour.\n",
    "\n",
    "So, (0,0,0) would be black, and (255,255,255) would be white. How would you represent blue, green or red?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Processing\n",
    "\n",
    "We have discovered that a computer sees images as arrays of pixel intensities, <br />\n",
    "and it is up to the computer vision developer (you) to make sense of that image.\n",
    "\n",
    "Let us dig into some of the more common image processing techniques that you may find useful. <br />\n",
    "For a more detailed discovery, some links will be provided at the end for you to dig even deeper.\n",
    "\n",
    "Oh wait, before that, can you think of some examples of how computer vision is used in the real world today? You will be discussing that as a class later so you might want to make some notes as you think."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Colour Spaces\n",
    "\n",
    "We talked about the Blue, Green and Red channels of the image earlier. What if we didn't need all the colours and just needed to know how light or dark an image was? Could we convert it to greyscale? How are greyscale images represented in Numpy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Grey\",grey)\n",
    "\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grey.shape)                         # Are these dimensions different from img.shape earlier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there less memory being used to store the image now that everything is in greyscale? <br />\n",
    "Does this mean that processing this image would potentially be faster since it has 1/3 the size of the original array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grey[300,400])          # What is the colour of the top left corner of the image? Notice that array indexing starts from 0\n",
    "print(grey[0,799])   # How does this compare to your previous finding above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grey[0,0])        # What is the colour of the top right corner of the image? \n",
    "                          # How does this compare to your previous finding above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun Fact: Do some colours actually appear darker than others when converted to greyscale? \n",
    "You can read up more about the different colour spaces at https://docs.opencv.org/4.0.0/de/d25/imgproc_color_conversions.html\n",
    "\n",
    "We will not be going too deep into the other colour spaces in this introductory workshop, but if you are interested, do read up the link above. And when you have more questions, you can use the Internet to help you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Thresholding, Masking and Region of Interest\n",
    "Earlier, we saw how some colours were darker than others. What if we were only interested in a part of the picture that was very dark or very light? Could we filter out just the square on the top right of the screen?\n",
    "\n",
    "**Technique 1: Greyscale Intensity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall that the square on the top right had a pixel intensity of 29\n",
    "# Now everything with a value greater than 29 will become 255\n",
    "ret,thresholded = cv2.threshold(grey,29,150,cv2.THRESH_BINARY)  \n",
    "cv2.imshow(\"Thresholded\",thresholded)\n",
    "\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The square that we want appears black, while the other parts of the image appears white. Usually, we would want the Regions of Interest (ROI) to be white, and the other areas black instead. Let us try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresholded = cv2.threshold(grey,29,255,cv2.THRESH_BINARY_INV)    #we use cv2.THRESH_BINARY_INV instead of cv2.THRESH_BINARY\n",
    "cv2.imshow(\"Thresholded\",thresholded)\n",
    "\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the use of this? You may ask. \n",
    "\n",
    "Well, thresholding the Region of Interest (ROI) can allow us to use it as a mask to display on the original image.\n",
    "\n",
    "**But what is a mask?**\n",
    "\n",
    "Let us take a look at the illustration below:\n",
    "\n",
    "<img src=\"images/image001_masking.jpg\" />\n",
    "\n",
    "In the image (in the middle) above, you can see the mask for the blue square on the top right corner. When we apply that mask (image in the middle) to the original image (image on the left), only the blue square is left in the masked image (image on the right).\n",
    "\n",
    "The mask layer helps to highlight the parts of the image that we are interested in. When the mask is applied to the image, only the parts that we are interested in are kept (white regions of the mask), while the remaining parts of the image are discarded. \n",
    "\n",
    "Fun Fact: You can also see this concept at work in popular image editing softwares such as Adobe Photoshop, where you can apply \"clipping masks\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked = cv2.bitwise_and(img, img, mask = thresholded)\n",
    "cv2.imshow(\"Masked\", masked)\n",
    "\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Did you manage to filter the blue square?\n",
    "\n",
    "Ok, time for you to experiment and see what else you would like to threshold. Can you threshold just the Circle in the middle?\n",
    "\n",
    "Hint: perhaps the grey layer is not the best layer to work with. Remember you have the original image:\n",
    "\n",
    "<img src=\"images/image001.png\" alt=\"Drawing\" style=\"width: 400px; border:1px solid; float:left;\"/>\n",
    "<div style=\"clear: both;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Technique 2: Colours.**<br />\n",
    "Remember that images are numpy arrays? And Numpy arrays can be filtered easily with advanced filters.\n",
    "\n",
    "To make our lives easier, we may want to change the white in the background to black instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = img.copy()                         # The masked image we are going to create\n",
    "(b,g,r) = cv2.split(img)                  # blue, green and red channels\n",
    "mask[(b==255)&(g==255)&(r==255)] = 0      # Set white background to 0. Remember that white is (255,255,255)\n",
    "\n",
    "cv2.imshow(\"Mask\",mask)\n",
    "\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets explore what the different layers of the mask looks like. They are the layers 0, 1 and 2 respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Blue Mask\",mask[:,:,0])       # Notice how the words are blue also\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Green Mask\",mask[:,:,1])\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Red Mask\",mask[:,:,2])\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Technique 3: Quick Numpy Array Manipulation based on position**\n",
    "\n",
    "There are some artifacts around the words for this green layer. Can we clean it up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[300:,:,1]=0                          # Remember that the image is a matrix. Let's wipe the bottom half to black (0)\n",
    "cv2.imshow(\"Green Mask\",mask[:,:,1])\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Red Mask\",mask[:,:,2])\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some artifacts around the words for this red layer also. Can we clean it up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[410:,:,2]=0\n",
    "cv2.imshow(\"Red Mask\",mask[:,:,2])\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simply get the objects based on colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 2 is the red layer. Rememeber (B,G,R)\n",
    "masked = cv2.bitwise_and(img,img,mask=mask[:,:,2])\n",
    "cv2.imshow(\"Circle\",masked)                   \n",
    "\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 1 is the green layer. Rememeber (B,G,R)\n",
    "masked = cv2.bitwise_and(img,img,mask=mask[:,:,1])\n",
    "cv2.imshow(\"Left Green Rectangle\",masked)\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 0 is the blue layer. Rememeber (B,G,R)\n",
    "masked = cv2.bitwise_and(img,img,mask=mask[:,:,0])\n",
    "cv2.imshow(\"Right Blue Rectangle\",masked)\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the words are also appearing not just the rectangle? This is because the words are also blue!\n",
    "\n",
    "If you don't want the words to appear, you can \"wipe\" it away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[300:,:,0]=0                          # Remember that the image is a matrix. Let's wipe the bottom half to black (0)\n",
    "masked = cv2.bitwise_and(img,img,mask=mask[:,:,0])\n",
    "cv2.imshow(\"Right Blue Rectangle\",masked)\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have spent quite a bit of time on masking, thresholding and regions of interest. There are different appraoches you can use, whether it is by colour, or by pixel intensity, or by manipulating the Numpy Array (e.g. for accessing and modifying parts of the image). Do take some time to practice these techniques and try it on different images.\n",
    "\n",
    "In computer vision, and in life, there are often multiple ways that you can reach the same objective. Can you think of more efficient ways to get your Region of Interest? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Geometric Transformations. Resizing and Cropping\n",
    "\n",
    "Moving on, perhaps the image is too big or too small, how might we resize it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets make the 800x600 image into a 400x300 image\n",
    "resized = cv2.resize(img,(400, 300))           # the second parameter is the desired dimensions you want (width,height)\n",
    "cv2.imshow(\"Resized\",resized)\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the shape now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the resize function can also be used to stretch the image, if you use a different aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets stretch the 800x600 image into a 200x300 image\n",
    "resized = cv2.resize(img,(200, 300))           # the second parameter is the desired dimensions you want (width,height)\n",
    "cv2.imshow(\"Resized\",resized)\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropping is an even simpler array function. Let's say we only want the top half of the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Cropped Top\",img[:300,:,:])\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we just wanted the right side of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Cropped Right\",img[:,400:,:])\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play around with it. Cropping to a Region of Interest would be more useful. Let's move on to another very useful method for extracting a Region of Interest (ROI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Contour Detection\n",
    "\n",
    "This is what is commonly used to search for regions of interest, typically using a thresholded mask. \n",
    "\n",
    "**But what is a contour?**\n",
    "\n",
    "To simplify this, think of all the black and white masks. A contour would be a group of connected white areas. Contour detection basically finds and returns these different groups as contours.\n",
    "\n",
    "To illustrate, how many connected regions of white do you think are there in the image below?\n",
    "\n",
    "<img src=\"images/image001_3contours.png\" style=\"width:400px; float:left;\" />\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "Did you guess that there are 3 contours detected? Let us try to load that image and draw the contour outlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 contours!\n"
     ]
    }
   ],
   "source": [
    "greytest = cv2.imread(\"images/image001_3contours.png\",0)    # Load that image\n",
    "contouroutlines = np.zeros(greytest.shape,dtype=\"uint8\")    # Create a blank canvas for drawing detected contours\n",
    "\n",
    "# Let's find the contours!\n",
    "(cnts,_) = cv2.findContours(greytest, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for (i, c) in enumerate(cnts):    \n",
    "    cv2.drawContours(contouroutlines, [c], -1, 255, 1)  # For each contour, draw just the outline of the contours\n",
    "    \n",
    "cv2.imshow(\"Contour Outlines\",contouroutlines)          # Display the results\n",
    "cv2.waitKey(0)                                          # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"There are \"+str(len(cnts))+\" contours!\")         # Print out the number of contours detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was a simple example with just 3 contours. \n",
    "\n",
    "How many contours would you expect to find on our thresholded original image?\n",
    "\n",
    "<img src=\"images/image001_allcontours.png\" style=\"width:400px; float:left;\" />\n",
    "<div style=\"clear:both;\"></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#We apply a threshold\n",
    "(T, thresholded) = cv2.threshold(grey, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Thresholded\",thresholded)\n",
    "\n",
    "# Let's find the contours!\n",
    "(cnts,_) = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "mask = np.zeros(img.shape,dtype=\"uint8\")  # Create a canvas for drawing detected contours\n",
    "for (i, c) in enumerate(cnts):    \n",
    "    cv2.drawContours(mask, [c], -1, (0,255,0), 1) \n",
    "    \n",
    "cv2.imshow(\"Mask\",mask)  \n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "print(\"There are \"+str(len(cnts))+\" contours!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are there 78 contours? That is because of the line of texts. \n",
    "\n",
    "Let us try to label the contours for us to visualize what is actually being counted.\n",
    "\n",
    "Below, you will see how each letter tends to forms 1 contour. But notice how some letters like \"i\" is actually counted as 2 contours since the top of the \"i\" and the bottom of the \"i\" are not connected. Similarly for the exclamation mark.\n",
    "\n",
    "The code below seems a little longer because code has been added for the annotations. You will understand the code better when you visit section 2.5 a little further below. In the meantime, do not worry about the code. Just run the code and see how the contours are counted. Take note of the red bounding boxes which have been drawn around each \"contour\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#We apply a threshold\n",
    "(T, thresholded) = cv2.threshold(grey, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Thresholded\",thresholded)\n",
    "\n",
    "# Let's find the contours!\n",
    "(cnts,_) = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = sorted(cnts, key=lambda cnts: cv2.boundingRect(cnts)[1])  #sort contours from top to bottom.\n",
    "\n",
    "mask = cv2.merge([thresholded,thresholded,thresholded])  # Create a canvas for drawing detected contours\n",
    "for (i, c) in enumerate(cnts):    \n",
    "    #cv2.drawContours(mask, [c], -1, (255,255,255), -1) \n",
    "    (x, y, w, h) = cv2.boundingRect(c)                   # Get the x,y coordinates of the contour's bounding box\n",
    "    cv2.rectangle(mask, (x,y), (x+w,y+h), (0,0,255))     # Draw the bounding boxes in red\n",
    "\n",
    "    cv2.putText(mask, \"\"+str(i+1), (x,y+28), cv2.FONT_HERSHEY_SIMPLEX, 0.25, (0,255,0), 1)\n",
    "    \n",
    "cv2.imshow(\"Mask\",mask)  \n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "print(\"There are \"+str(len(cnts))+\" contours!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to find out more about contours? You can visit https://docs.opencv.org/3.3.1/d4/d73/tutorial_py_contours_begin.html to dig deeper. As always, do continue searching on the Internet because there is a treasure trove of information out there, and it will be very useful as you go deeper!\n",
    "\n",
    "Tip: In the above examples, we used cv2.RETR_EXTERNAL to get the external contours. There are also other options that you can specify to get different types of contours. For example, cv2.RETR_LIST will list all contours and not just the external contours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Contours as Image Masks**\n",
    "\n",
    "Remember we talked about image masks earlier? The contours can be used to create masks too! \n",
    "\n",
    "Set the last parameter for the drawContour function to -1 to create a fill (instead of an outline), and use it as a mask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(T, thresholded) = cv2.threshold(grey, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "thresholded[410:,:]=0                     # Shortcut to remove the text since it is on the bottom half of the image!\n",
    "#cv2.imshow(\"Thresholded\",thresholded)\n",
    "\n",
    "#How many contours do you think there are?\n",
    "(cnts,_) = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "mask = np.zeros(thresholded.shape,dtype=\"uint8\")\n",
    "for (i, c) in enumerate(cnts):    \n",
    "    cv2.drawContours(mask, [c], -1, 255, -1)  #the last parameter defines the outline thickness. -1 will fill the contour\n",
    "    \n",
    "cv2.imshow(\"Mask\",mask)\n",
    "cv2.imshow(\"Masked Image\",cv2.bitwise_and(img,img,mask=mask))  \n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "print(\"There are \"+str(len(cnts))+\" contours!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you find it easier than manually thresholding each colour?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Drawing Lines and Writing Texts\n",
    "\n",
    "We actually did a bit of this in the contour exercise above, using a method called drawContour. Let us see how we can add lines and words into images, since we may want to annotate our images. Let's revisit the example in 2.4 and add labels to our contours!\n",
    "\n",
    "Only the 3 lines that have changed are commented below. The other lines of code as similar to the example in 2.4 and you can refer to that example to recap what those lines of code do.\n",
    "\n",
    "First, we get the bounding box for each contour, draw a rectangle around it, and then add the text to label each contour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greytest = cv2.imread(\"images/image001_3contours.png\",0)\n",
    "contouroutlines = np.zeros(greytest.shape,dtype=\"uint8\")\n",
    "\n",
    "(cnts,_) = cv2.findContours(greytest, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for (i, c) in enumerate(cnts):    \n",
    "    cv2.drawContours(contouroutlines, [c], -1, 255, 1)\n",
    "\n",
    "    # GET BOUNDING BOX OF EACH CONTOUR\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    \n",
    "    # DRAW A RECTANGLE AROUND EACH CONTOUR (I.E. DRAW THE BOUNDING BOX)\n",
    "    cv2.rectangle(contouroutlines, (x, y), (x+w, y+h), (255,255,0), 2) \n",
    "    \n",
    "    # ADD THE TEXT \"COUNTOUR <>\" TO EACH CONTOUR\n",
    "    cv2.putText(contouroutlines, \"Contour \"+str(i+1), (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
    "\n",
    "    \n",
    "cv2.imshow(\"Contour Outlines\",contouroutlines)          \n",
    "cv2.waitKey(0)                                          \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"There are \"+str(len(cnts))+\" contours!\")         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details on writing text on screen, and drawing shapes such as rectangles and circles, you can visit https://docs.opencv.org/4.0.0/dc/da5/tutorial_py_drawing_functions.html\n",
    "\n",
    "If you later create applications for object detection, you can use this method to annotate what you actually detect. Or you could also create your own art work and images using just code! \n",
    "\n",
    "Let's try to draw something from scratch:\n",
    "\n",
    "**ACCESS DENIED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty canvas (height,width,channels) - In this case: 3 colour channels, width 400, and height 300 \n",
    "canvas_accessdenied = np.zeros((600,800,3),dtype=\"uint8\")      \n",
    "\n",
    "# Add a Hollow Rectangle at (x=100,y=230) with the colour (255,255,0), and line thickness 2 \n",
    "cv2.rectangle(canvas_accessdenied, (100, 230), (700, 370), (255,255,0), 2)  \n",
    "\n",
    "# Add your Text at (x=150,y=320) the colour (100,100,255), fint size 2, and line thickness 5 \n",
    "cv2.putText(canvas_accessdenied, \"ACCESS DENIED\", (150,320), cv2.FONT_HERSHEY_SIMPLEX, 2, (100,100,255), 5)\n",
    "\n",
    "cv2.imshow(\"Canvas Access Denied\",canvas_accessdenied)  \n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about doing one for Access Granted?\n",
    "\n",
    "**ACCESS GRANTED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty canvas (height,width,channels) - In this case: 3 colour channels, width 400, and height 300 \n",
    "canvas_accessgranted = np.zeros((600,800,3),dtype=\"uint8\")      \n",
    "\n",
    "# Add a Hollow Rectangle at (x=100,y=230) with the colour (255,255,0), and line thickness 2 \n",
    "cv2.rectangle(canvas_accessgranted, (100, 230), (700, 370), (255,255,0), 2)  \n",
    "\n",
    "# Add your Text at (x=130,y=320) the colour (255,100,100), fint size 2, and line thickness 5 \n",
    "cv2.putText(canvas_accessgranted, \"ACCESS GRANTED\", (130,320), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,100,100), 5)\n",
    "\n",
    "cv2.imshow(\"Canvas Access Granted\",canvas_accessgranted)  \n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try creating your own graphics with just code! It could be \"Welcome Back\" or something!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! \n",
    "\n",
    "## It's time for you to start creating some fun stuff! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh wait, anytime you need some help, or if you need to know the syntax of the openCv functions, <br />\n",
    "do look it up at https://docs.opencv.org/4.0.0/d2/d96/tutorial_py_table_of_contents_imgproc.html\n",
    "\n",
    "If you can't find your answers there, there's also a good chance someone else has the answer. Get comfortable using the Internet to find out more!\n",
    "\n",
    "Keep finding solutions to your questions, and keep building good stuff to help with the many challenges out there in the world!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Expand on the video example in section 1.1b, resize the video to 800x600 and display it in greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Use the Python time library, and add a timestamp neatly to the video feed from your webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Code for getting a timestamp. Search online for more options if you need.\n",
    "from datetime import datetime\n",
    "print (datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Using the red and green markers, create different coloured cards. Can you get the computer to recognize whenever a card of a particular colour is presented?\n",
    "\n",
    "Hint: First take a few pictures of the cards, then use simple image processing to analyze their colour patterns. Explore different colour spaces if necessary. Notice how this system might also be rather susceptible to changes in lighting conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Create an application that displays \"ACCESS GRANTED\" whenever you appear (or do something, or show something) in front of the camera \n",
    "\n",
    "Exercise your creativity. The only rule is that you are not allowed to touch the keyboard, and it needs to involve the camera processing the video feed.\n",
    "\n",
    "Challenge. Create something that only grants access to you, and does not grant access to friends who try to pose as you!\n",
    "First you will demonstrate gaining access to the system, 2 times. Then your friend will try to do the same. If your friend does not manage to gain access within 3 minutes, you win!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Watch the video at https://www.youtube.com/watch?v=xyfSUOfFI_E \n",
    "List down ideas of what you may like to create using the powers of Computer Vision. <br />\n",
    "Can some of your ideas help to achieve the Sustainable Development Goals (SDG)?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: List down at least 3 examples of Computer Vision applications that you have seen in the real world"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: List down some of the limitations of the system that you created in Task 4\n",
    "How do you think it can be improved?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
